{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RuaVFOSSbqNY"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Convolution2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Flatten"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "p6Zav-KbdbH1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)\n",
        "print(x_train.class_indices)\n",
        "model=Sequential()\n",
        "#adding convolution layer(no.of filters,filter size,input shape,activation function)\n",
        "model.add(Convolution2D(32,(3,3),input_shape=(64,64,3),activation=\"relu\"))\n",
        "#adding max pooling layer(pool_size)\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#input layer of ann\n",
        "model.add(Flatten())\n",
        "#add hidden layer(no.of neurons,activation=relu,weights)\n",
        "model.add(Dense(units=128,activation=\"relu\"))\n",
        "#add output layer(no.of output classes=5,activation function=softmax)\n",
        "model.add(Dense(units=5,activation=\"softmax\"))\n",
        "model.summary()\n",
        "#configure the learning process(loss fucntion,accuracy,optimizer)\n",
        "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
        "model.fit(x_train,steps_per_epoch=47,epochs=1,validation_data=x_test,validation_steps=20)\n",
        "model.save(\"animal.h5\")\n",
        "from tensorflow.keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "model=load_model(\"animal.h5\")\n",
        "img=image.load_img(r\"/content/drive/MyDrive/DL_dataset/Crop-animal data/testset/crows/2Q__ (1).jpeg\")\n",
        "x=image.img_to_array(img)\n",
        "x\n",
        "x.shape\n",
        "x=np.expand_dims(x,axis=0)\n",
        "x.shape\n",
        "y=model.predict(x)\n",
        "pred=np.argmax(y, axis=1)\n",
        "y\n",
        "pred\n",
        "x_train.class_indices\n",
        "index=['bears', 'crows', 'elephants', 'racoons', 'rats']\n",
        "result=str(index[pred[0]])\n",
        "result\n"
      ],
      "metadata": {
        "id": "W-rXF0CzdhqB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}